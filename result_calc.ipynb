{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from utils.post_process import ProcessPred\n",
    "import os\n",
    "import csv\n",
    "from result_replication_src.gen_nat_scl_eval import ProcGenSclNatRes\n",
    "from result_replication_src.mvp_eval import ProcMvpRes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scl_nat_file = './final_result/acos-comparison/ours24_gen_scl_nat2.json'\n",
    "gold_annot_res = './final_result/gold_annotations_fin_3.csv'\n",
    "mapping_path = './final_result/mappings_for_comparison/gen_sch_nat/gen_sch_nat_map.json'\n",
    "\n",
    "gen_scl_nat_processor =  ProcGenSclNatRes(gen_scl_nat_file, gold_annot_res, mapping_path)\n",
    "# gen_scl_nat_processor.calc_comp_em_uoce()\n",
    "# gen_scl_nat_processor.calc_comp_em_acos(mode='aste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_file = './final_result/acos-comparison/ours24_mvp.json'\n",
    "mapping_path = './final_result/mappings_for_comparison/gen_sch_nat/gen_sch_nat_map.json'\n",
    "mvp_processor =  ProcMvpRes(mvp_file, gold_annot_res)\n",
    "# mvp_processor.calc_comp_em_uoce()\n",
    "# mvp_processor.calc_comp_em_acos(mode='aste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTE RES: (Component-Level Exact Match)\n",
      "MVP --> precision: 0.6126126126126128, recall: 0.6766169154228857, f1 score: 0.6430260047281325\n",
      "GEN_SCL_NAT--> precision: 0.6025641025641025, recall: 0.7014925373134329, f1 score: 0.6482758620689655\n",
      "\n",
      "\n",
      "ASTE RES: (Tuple-Level Exact Match)\n",
      "MVP --> precision: 0.3310810810810811, recall: 0.3656716417910448, f1 score: 0.3475177304964539\n",
      "GEN_SCL_NAT--> precision: 0.32679738562091504, recall: 0.373134328358209, f1 score: 0.34843205574912894\n",
      "\n",
      "\n",
      "ACOS RES: (Component-Level Exact Match)\n",
      "MVP --> precision: 0.5283783783783783, recall: 0.5835820895522387, f1 score: 0.5546099290780141\n",
      "GEN_SCL_NAT--> precision: 0.4961538461538461, recall: 0.5776119402985074, f1 score: 0.5337931034482758\n",
      "\n",
      "\n",
      "ACOS RES: (Tuple-Level Exact Match)\n",
      "MVP --> precision: 0.12837837837837837, recall: 0.1417910447761194, f1 score: 0.13475177304964536\n",
      "GEN_SCL_NAT--> precision: 0.03205128205128205, recall: 0.03731343283582089, f1 score: 0.034482758620689655\n"
     ]
    }
   ],
   "source": [
    "print(\"ASTE RES: (Component-Level Exact Match)\")\n",
    "\n",
    "p, r, f1 = mvp_processor.calc_comp_em_acos(mode='aste')\n",
    "print(f\"MVP --> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "p, r, f1 = gen_scl_nat_processor.calc_comp_em_acos(mode='aste')\n",
    "print(f\"GEN_SCL_NAT--> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"ASTE RES: (Tuple-Level Exact Match)\")\n",
    "p, r, f1 = mvp_processor.calc_tup_em_acos(mode='aste')\n",
    "print(f\"MVP --> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "p, r, f1 = gen_scl_nat_processor.calc_tup_em_acos(mode='aste')\n",
    "print(f\"GEN_SCL_NAT--> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"ACOS RES: (Component-Level Exact Match)\")\n",
    "p, r, f1 = mvp_processor.calc_comp_em_acos(mode='acos')\n",
    "print(f\"MVP --> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "p, r, f1 = gen_scl_nat_processor.calc_comp_em_acos(mode='acos')\n",
    "print(f\"GEN_SCL_NAT--> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"ACOS RES: (Tuple-Level Exact Match)\")\n",
    "p, r, f1 = mvp_processor.calc_tup_em_acos(mode='acos')\n",
    "print(f\"MVP --> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "p, r, f1 = gen_scl_nat_processor.calc_tup_em_acos(mode='acos')\n",
    "print(f\"GEN_SCL_NAT--> precision: {p}, recall: {r}, f1 score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UOC RESULTS (COMPONENT LEVEL)\n",
      "\n",
      "\n",
      "MVP --> precision: 0.35608108108108094, recall: 0.3932835820895521, f1 score: 0.3737588652482268\n",
      "\n",
      "\n",
      "GEN_SCL_NAT--> precision: 0.39102564102564075, recall: 0.45522388059701463, f1 score: 0.4206896551724135\n"
     ]
    }
   ],
   "source": [
    "print(\"UOC RESULTS (COMPONENT LEVEL)\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "p, r, f1 = mvp_processor.calc_comp_em_uoce()\n",
    "print(f\"MVP --> precision: {p}, recall: {r}, f1 score: {f1}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "p, r, f1 = gen_scl_nat_processor.calc_comp_em_uoce()\n",
    "print(f\"GEN_SCL_NAT--> precision: {p}, recall: {r}, f1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./evaluations/') \n",
    "\n",
    "GOLD_PATH = './final_result/gold_annotations_fin_3.csv'\n",
    "# PRED_PATH = '../ontology_experiments/results/final_results/llama_70B_owl.csv'\n",
    "from opinion_overlap_eval import OpinionEval\n",
    "import os\n",
    "dict_pol = {\n",
    "    'POS': 'positive',\n",
    "    'NEG': 'negative',\n",
    "    'NEU': 'neutral'\n",
    "}\n",
    "columns_incls = ['id', 'raw_text', 'aspect_term', 'sentiment_expression', 'target_entity', 'aspect_category', 'sentiment_polarity', 'opinion_holder_span', 'opinion_holder_entity', 'sentiment_intensity', 'opinion_qualifier', 'opinion_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_dir = './final_result/'\n",
    "mods = os.listdir(pred_model_dir)\n",
    "owl_res = 'onto_prompt'\n",
    "nat_lang_res = 'nlprompt'\n",
    "op_eval = OpinionEval(columns_incls)\n",
    "gold_df = pd.read_csv(GOLD_PATH).replace({'sentiment_polarity': dict_pol})\n",
    "fine_res_rows = []\n",
    "for mod in mods:\n",
    "    \n",
    "    if mod not in ['.DS_Store', 'acos-comparison', 'gold_annotations_fin_3.csv', 'mappings_for_comparison']:\n",
    "        mod_dir_path = os.path.join(pred_model_dir, mod)\n",
    "        \n",
    "        owl_res_path = os.path.join(mod_dir_path, owl_res, 'csv')\n",
    "        nat_lang_path = os.path.join(mod_dir_path, nat_lang_res, 'csv')\n",
    "        for owl_file in os.listdir(owl_res_path):\n",
    "            pred_df = pd.read_csv(os.path.join(owl_res_path, owl_file))\n",
    "            scores = op_eval.eval_opinions(gold_df, pred_df)\n",
    "            fine_res_rows.append([mod, 'owl', owl_file.replace('.csv', ''), round(scores['precision']*100, 2), round(scores['recall']*100, 2), round(scores['f1']*100, 2)])\n",
    "        for nat_file in os.listdir(nat_lang_path):\n",
    "            pred_df = pd.read_csv(os.path.join(nat_lang_path, nat_file))\n",
    "            scores = op_eval.eval_opinions(gold_df, pred_df)\n",
    "            fine_res_rows.append([mod, 'natlang', nat_file.replace('.csv', ''), round(scores['precision']*100, 2), round(scores['recall']*100, 2), round(scores['f1']*100, 2)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fine_res_rows, columns=['model', 'prompt', 'variation',  'precision', 'recall', 'f1'])\n",
    "owl_res = df[df['prompt'] == 'owl']\n",
    "natlang_res = df[df['prompt'] == 'natlang']\n",
    "owl_rearg = owl_res.pivot_table(values='f1', index=['model'], columns='variation')\n",
    "natlang_rearg = natlang_res.pivot_table(values='f1', index=['model'], columns='variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontoprompt Scores with Different Serialisation Formats\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "jsonld",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "manchester_owl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "obo_format",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "owl_funct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "owl_xml",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rdf_xml",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttl_syntax",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "23f6ed86-5a38-439c-91a0-826fcc969ff4",
       "rows": [
        [
         "gemma2_27b",
         "47.8",
         "47.12",
         "47.99",
         "46.24",
         "48.3",
         "46.13",
         "48.97"
        ],
        [
         "gemma2_9b",
         "45.55",
         "45.63",
         "45.1",
         "36.4",
         "45.15",
         "37.07",
         "45.64"
        ],
        [
         "gpt-4o",
         "48.09",
         "47.01",
         "47.89",
         "48.04",
         "46.67",
         "47.87",
         "48.44"
        ],
        [
         "gpt-4o-mini",
         "46.05",
         "45.31",
         "43.92",
         "44.95",
         "45.26",
         "44.77",
         "44.78"
        ],
        [
         "llama_70b",
         "42.83",
         "41.93",
         "43.5",
         "43.05",
         "41.18",
         "42.72",
         "42.42"
        ],
        [
         "llama_8b",
         "41.32",
         "42.42",
         "41.16",
         "40.87",
         "41.18",
         "41.98",
         "41.09"
        ],
        [
         "mistral_7b",
         "40.89",
         "39.98",
         "39.92",
         "39.54",
         "40.44",
         "39.37",
         "39.39"
        ],
        [
         "mixtral_8x7b",
         "43.12",
         "42.32",
         "41.98",
         "41.88",
         "42.19",
         "40.99",
         "42.8"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variation</th>\n",
       "      <th>jsonld</th>\n",
       "      <th>manchester_owl</th>\n",
       "      <th>obo_format</th>\n",
       "      <th>owl_funct</th>\n",
       "      <th>owl_xml</th>\n",
       "      <th>rdf_xml</th>\n",
       "      <th>ttl_syntax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma2_27b</th>\n",
       "      <td>47.80</td>\n",
       "      <td>47.12</td>\n",
       "      <td>47.99</td>\n",
       "      <td>46.24</td>\n",
       "      <td>48.30</td>\n",
       "      <td>46.13</td>\n",
       "      <td>48.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma2_9b</th>\n",
       "      <td>45.55</td>\n",
       "      <td>45.63</td>\n",
       "      <td>45.10</td>\n",
       "      <td>36.40</td>\n",
       "      <td>45.15</td>\n",
       "      <td>37.07</td>\n",
       "      <td>45.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>48.09</td>\n",
       "      <td>47.01</td>\n",
       "      <td>47.89</td>\n",
       "      <td>48.04</td>\n",
       "      <td>46.67</td>\n",
       "      <td>47.87</td>\n",
       "      <td>48.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>46.05</td>\n",
       "      <td>45.31</td>\n",
       "      <td>43.92</td>\n",
       "      <td>44.95</td>\n",
       "      <td>45.26</td>\n",
       "      <td>44.77</td>\n",
       "      <td>44.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_70b</th>\n",
       "      <td>42.83</td>\n",
       "      <td>41.93</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.05</td>\n",
       "      <td>41.18</td>\n",
       "      <td>42.72</td>\n",
       "      <td>42.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_8b</th>\n",
       "      <td>41.32</td>\n",
       "      <td>42.42</td>\n",
       "      <td>41.16</td>\n",
       "      <td>40.87</td>\n",
       "      <td>41.18</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral_7b</th>\n",
       "      <td>40.89</td>\n",
       "      <td>39.98</td>\n",
       "      <td>39.92</td>\n",
       "      <td>39.54</td>\n",
       "      <td>40.44</td>\n",
       "      <td>39.37</td>\n",
       "      <td>39.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral_8x7b</th>\n",
       "      <td>43.12</td>\n",
       "      <td>42.32</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.88</td>\n",
       "      <td>42.19</td>\n",
       "      <td>40.99</td>\n",
       "      <td>42.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variation     jsonld  manchester_owl  obo_format  owl_funct  owl_xml  rdf_xml  \\\n",
       "model                                                                           \n",
       "gemma2_27b     47.80           47.12       47.99      46.24    48.30    46.13   \n",
       "gemma2_9b      45.55           45.63       45.10      36.40    45.15    37.07   \n",
       "gpt-4o         48.09           47.01       47.89      48.04    46.67    47.87   \n",
       "gpt-4o-mini    46.05           45.31       43.92      44.95    45.26    44.77   \n",
       "llama_70b      42.83           41.93       43.50      43.05    41.18    42.72   \n",
       "llama_8b       41.32           42.42       41.16      40.87    41.18    41.98   \n",
       "mistral_7b     40.89           39.98       39.92      39.54    40.44    39.37   \n",
       "mixtral_8x7b   43.12           42.32       41.98      41.88    42.19    40.99   \n",
       "\n",
       "variation     ttl_syntax  \n",
       "model                     \n",
       "gemma2_27b         48.97  \n",
       "gemma2_9b          45.64  \n",
       "gpt-4o             48.44  \n",
       "gpt-4o-mini        44.78  \n",
       "llama_70b          42.42  \n",
       "llama_8b           41.09  \n",
       "mistral_7b         39.39  \n",
       "mixtral_8x7b       42.80  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Ontoprompt Scores with Different Serialisation Formats')\n",
    "owl_rearg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPROMPT Scores with Different Serialisation Formats\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "desc_eg_format",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "desc_format_eg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eg_desc_format",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eg_format_desc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "format_desc_eg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "format_eg_desc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "30708a9b-067d-46e0-880b-9fe74e447adf",
       "rows": [
        [
         "gemma2_27b",
         "48.08",
         "46.6",
         "47.3",
         "47.3",
         "45.96",
         "44.7"
        ],
        [
         "gemma2_9b",
         "47.67",
         "46.54",
         "48.8",
         "48.67",
         "46.13",
         "45.39"
        ],
        [
         "gpt-4o",
         "48.72",
         "46.32",
         "49.27",
         "49.44",
         "47.96",
         "47.3"
        ],
        [
         "gpt-4o-mini",
         "45.56",
         "44.9",
         "46.32",
         "47.5",
         "44.41",
         "46.89"
        ],
        [
         "llama_70b",
         "39.08",
         "38.35",
         "40.04",
         "36.78",
         "37.38",
         "38.56"
        ],
        [
         "llama_8b",
         "38.63",
         "41.57",
         "36.54",
         "37.27",
         "40.66",
         "29.62"
        ],
        [
         "mistral_7b",
         "40.0",
         "40.44",
         "40.9",
         "40.38",
         "41.34",
         "41.92"
        ],
        [
         "mixtral_8x7b",
         "41.35",
         "42.14",
         "43.2",
         "42.71",
         "41.34",
         "42.49"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variation</th>\n",
       "      <th>desc_eg_format</th>\n",
       "      <th>desc_format_eg</th>\n",
       "      <th>eg_desc_format</th>\n",
       "      <th>eg_format_desc</th>\n",
       "      <th>format_desc_eg</th>\n",
       "      <th>format_eg_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma2_27b</th>\n",
       "      <td>48.08</td>\n",
       "      <td>46.60</td>\n",
       "      <td>47.30</td>\n",
       "      <td>47.30</td>\n",
       "      <td>45.96</td>\n",
       "      <td>44.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma2_9b</th>\n",
       "      <td>47.67</td>\n",
       "      <td>46.54</td>\n",
       "      <td>48.80</td>\n",
       "      <td>48.67</td>\n",
       "      <td>46.13</td>\n",
       "      <td>45.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>48.72</td>\n",
       "      <td>46.32</td>\n",
       "      <td>49.27</td>\n",
       "      <td>49.44</td>\n",
       "      <td>47.96</td>\n",
       "      <td>47.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>45.56</td>\n",
       "      <td>44.90</td>\n",
       "      <td>46.32</td>\n",
       "      <td>47.50</td>\n",
       "      <td>44.41</td>\n",
       "      <td>46.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_70b</th>\n",
       "      <td>39.08</td>\n",
       "      <td>38.35</td>\n",
       "      <td>40.04</td>\n",
       "      <td>36.78</td>\n",
       "      <td>37.38</td>\n",
       "      <td>38.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_8b</th>\n",
       "      <td>38.63</td>\n",
       "      <td>41.57</td>\n",
       "      <td>36.54</td>\n",
       "      <td>37.27</td>\n",
       "      <td>40.66</td>\n",
       "      <td>29.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral_7b</th>\n",
       "      <td>40.00</td>\n",
       "      <td>40.44</td>\n",
       "      <td>40.90</td>\n",
       "      <td>40.38</td>\n",
       "      <td>41.34</td>\n",
       "      <td>41.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral_8x7b</th>\n",
       "      <td>41.35</td>\n",
       "      <td>42.14</td>\n",
       "      <td>43.20</td>\n",
       "      <td>42.71</td>\n",
       "      <td>41.34</td>\n",
       "      <td>42.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variation     desc_eg_format  desc_format_eg  eg_desc_format  eg_format_desc  \\\n",
       "model                                                                          \n",
       "gemma2_27b             48.08           46.60           47.30           47.30   \n",
       "gemma2_9b              47.67           46.54           48.80           48.67   \n",
       "gpt-4o                 48.72           46.32           49.27           49.44   \n",
       "gpt-4o-mini            45.56           44.90           46.32           47.50   \n",
       "llama_70b              39.08           38.35           40.04           36.78   \n",
       "llama_8b               38.63           41.57           36.54           37.27   \n",
       "mistral_7b             40.00           40.44           40.90           40.38   \n",
       "mixtral_8x7b           41.35           42.14           43.20           42.71   \n",
       "\n",
       "variation     format_desc_eg  format_eg_desc  \n",
       "model                                         \n",
       "gemma2_27b             45.96           44.70  \n",
       "gemma2_9b              46.13           45.39  \n",
       "gpt-4o                 47.96           47.30  \n",
       "gpt-4o-mini            44.41           46.89  \n",
       "llama_70b              37.38           38.56  \n",
       "llama_8b               40.66           29.62  \n",
       "mistral_7b             41.34           41.92  \n",
       "mixtral_8x7b           41.34           42.49  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('NLPROMPT Scores with Different Serialisation Formats')\n",
    "natlang_rearg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
